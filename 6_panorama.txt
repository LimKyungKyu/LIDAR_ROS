// 1. 파노라마 //
// 입력 영상에서 특징점을 검출하고, 서로 매칭을 수행하여 호모그래피를 구해야한다. //
// 구해진 호모그래피 행렬을 기반으로 입력 영상을 변형하여 서로 이어붙이는 작업을 수행한다. // 
// 따라서 //
// 서로 일정 비율 이상으로 겹치는 영역과 //
// 서로 같은 위치를 분간할 수 있도록 유효한 특징점이 많이 있어야한다. //
// + 이어붙인 영상의 밝기를 적절하게 보정하여 자연스럽게 보이기 위해서 블렌딩 처리를 추가할 수 있다. //





// 2. 선언 : opencv의 Stitcher 클래스를 사용한다. //
Ptr<Stitcher> my_stitcher = Stitcher::creat();

// Stitcher::creat()의 인자 //
// Stitcher::creat(Stitcher::PANORAMA) : 디폴트 이다.
// Stitcher::creat(); 이렇게 아무것도 안쓰면 디폴트 값이 적용된다.
// 입력 영상들이 투시변환 또는 호모그래피 관계에 있다고 가정한다.
// 투시변환은 평행은 유지하지 않지만 직선은 유지한다.
// 이미지의 투사점이 이동한다고 보면 된다.
// 호모그래피는 3차원 공간상의 평면을 서로 다른 위치에서 볼때의 관계를 나타내는 용어이다.
// 따라서 투시변환 또는 호모그래피의 관계에 있다고 가정하는것이다.
// Stitcher::creat(Stitcher::SCAN) : 스캐너등으로 스캔한 여러장의 영상을 이어붙이는 기능이다.
// 입력 영상들이 서로 어파인 변환 관계라고 가정한다.
// 어파인변환은 변환 전과 변환 후가 직선과 평행을 유지한다. ( 정사각형이 마름모로 변하듯 )






// 3. 활용 : 영상을 실제로 이어붙이기 위한 함수 Stitcher::stitch() // 
Stitcher::Status result_status = my_stitcher->stitch(imgs,dst);

// int data가 int형 data이듯 Stitcher::stitch()는 아래와 같은 관계를 가진다. 
// Stitcher::Status형 Stitcher::stitch(인풋 데이터, 아웃풋 데이터)
// 인풋 데이터에서 ORB 특징점을 찾아 서로 매칭하고 호모그래피 행렬을 계산한다.
// 계산된 호모그래피 행렬을 이용하여 인접한 영상을 적절하게 투시변환한다.
// 이어붙인 부분의 밝기를 적절하게 보정하여 아웃풋 데이터를 반환한다.
// my_stitcher->stitch(imgs,dst) 이 항목이 정상적으로 작동하면
// result_status에 Stitcher::Status::OK 상수를 반환한다.




// 4. 예제 : https://github.com/gilbutITbook/006939의 ch14/stitching
// main.cpp, img1.jpg, img2.jpg, img3.jpg 다운로드한다.
// main.cpp //
#include "opencv2/opencv.hpp"
#include <iostream>

using namespace cv;
using namespace std;

int main(int argc, char* argv[])
{
	// img1.jpg, img2.jpg, img3.jpg 합쳐야 되므로
	// argc는 반드시 4여야한다.
	if (argc < 3) {
		cerr << "Usage: stitching.exe <image_file1> <image_file2> [<image_file3> ...]" << endl;
		return -1;
	}



	// 파일을 Mat img에 저장하고
	// vector<Mat> imgs에 img1,img2,img3을 순서대로 push_back 한다.

	vector<Mat> imgs;
	for (int i = 1; i < argc; i++) {
		Mat img = imread(argv[i]);

		if (img.empty()) {
			cerr << "Image load failed!" << endl;
			return -1;
		}

		imgs.push_back(img);
	}

	// 파노라마를 수행하기 위해 클래스를 호출한다.
	Ptr<Stitcher> stitcher = Stitcher::create();

	// 실제 파노라마를 수행하는 stitch를 stitcher에서 꺼내서 사용한다.
	// imgs는 인풋, dst는 아웃풋 
	// stitcher->stitch(imgs, dst) 작업이 성공하면
	// status에 Stitcher::Status::OK를 반환한다, if 문에서 응용방법을 확인할 수 있다.
	Mat dst;
	Stitcher::Status status = stitcher->stitch(imgs, dst);

	if (status != Stitcher::Status::OK) {
		cerr << "Error on stitching!" << endl;
		return -1;
	}

	// dst결과를 result.jpg로 저장한다.
	imwrite("result.jpg", dst);

	imshow("dst", dst);

	waitKey();
	return 0;
}
// CMakeLists.txt //
cmake_minimum_required(VERSION 2.8)
project(stitching)
find_package(OpenCV REQUIRED)
include_directories(${OpenCV_INCLUDE_DIRS})
add_executable(stitching main.cpp)
target_link_libraries(stitching ${OpenCV_LIBS})
// CMakeLists.txt가 있는 폴더에서 터미널 키고
cmake CMakeLists.txt && make
./stitching img1.jpg img2.jpg img3.jpg























//////////////////////////////////////////////////////////////////////////////////////////////////////////////
// 5. 코드에 적용 해보기 // 
#include "ros/ros.h"
#include "sensor_msgs/LaserScan.h"
#include <math.h>
#include <opencv2/opencv.hpp>
#include "tf/transform_listener.h"
#include "project_ros_cpp/get_degree.h"
#define _USE_MATH_DEFINES
#include <cstdio>
#define RAD2DEG(x) ((x)*180.0/M_PI)


using namespace cv;
using namespace std;


// 초기 맵 세팅 //
// 중심 (20, 20) //
// 창1 : 전체 맵 사이즈 40x40 //
// + 창1 : 확대 15배, 1m = 15px, #define enlarge 15 //
// + 창1 : 확대 후, 상하좌우 검은색 패딩(확대 후 매트릭스의 상하좌우 여백), #define padding 10 //
// 1픽셀 = 1m, 15배 확대햇으면 15픽셀 = 1m 이다.
#define enlarge 15
#define padding 0
Mat my_map(40*enlarge, 40*enlarge, CV_32FC1, Scalar(0)); // 40x40을 15배확대, float32형 3채널, 0 = 검은색으로 채운다.
Mat re_map(40*enlarge, 40*enlarge, CV_32FC1, Scalar(0)); // 초기화를 위한 맵 변수 선언
Mat my_map_ch3; // 3채널 변환을 위한 맵 변수 선언
Mat my_map_rotation; // 회전을 위한 맵 변수 선언
int re_map_count = 0; // 맵 초기화 카운트를 위한 변수 선언


// 초기 좌표, 좌표계 세팅 //
Point2d my_center(my_map.size().width/2, my_map.size().height/2); // 초기 중심 좌표
Point2d carto_center; // 카토그래퍼 호환 좌표
Point2d my_axis_x(my_map.size().width/8,0); // x축 좌표계
Point2d my_axis_y(0,my_map.size().height/8); // y축 좌표계
Point2d my_axis_x_rotation, my_axis_y_rotation; // IMU 회전 좌표계
int re_axis_count = 0; // 좌표축 갱신을 위한 선언

int m_a_count = 0; // 유효한 거리값 개수 확인을 위한 선언
Point2d detection; // 유효한 좌표저장을 위한 변수 선언

// IMU각도 저장을 위한 변수 선언 
float get_roll = 0.0;
float get_pitch = 0.0;
float get_yaw = 0.0;



// 카토그래퍼에서 좌표를 받는 함수 //
void from_cartographer_get_point()
{
	tf::TransformListener tfl;
	tf::StampedTransform for_get_coordinate;
	tf::Vector3 Coordinate_3D;

	tfl.waitForTransform("/odom", "/base_footprint", ros::Time(), ros::Duration(1.0));
	tfl.lookupTransform("/odom", "/base_footprint", ros::Time(), for_get_coordinate);
	Coordinate_3D = for_get_coordinate.getOrigin();

	//std::cout<<"시작 점으로 부터 현재 위치 [metric] (x, y, z)"<<std::endl;
	//std::cout<<"("<<Coordinate_3D.getX()<<", "<<Coordinate_3D.getY()<<", "<<Coordinate_3D.getZ()<<")"<<std::endl;

	// 이동한 만큼 센터를 수정
	carto_center.x = my_center.x + Coordinate_3D.getX()*enlarge;
	carto_center.y = my_center.y + Coordinate_3D.getY()*enlarge;
	printf("(x, y) : [%.3f, %.3f]\n", carto_center.x , carto_center.y);
}

// IMU에서 각도를 받는 함수 //
void get_degree_from_imu(const project_ros_cpp::get_degree::ConstPtr& msg)
{
	// msg에서 data를 꺼낸다.
	// degree로 주어진다.
	get_roll = msg->roll;
	get_pitch = msg->pitch;
	get_yaw = msg->yaw;
	printf("get degree : %f, %f, %f\n", get_roll, get_pitch, get_yaw);
}

// 포인트 회전을 위한 함수 //
Point2d point_rotation(Point2d a, float b)
{
	// float b 는 라디안이 입력되야한다.

	Point2d temp_a(a.x,a.y);

	temp_a.x = a.x*cos(b) - a.y*sin(b);
	temp_a.y = a.x*sin(b) + a.y*cos(b);

	//std::cout<<temp_a.x<<" "<<temp_a.y<< std::endl;
	return temp_a;
}

// 좌표축 회전을 위한 함수 //
void from_IMU_modify_axis()
{
	//printf("\nhere? Tag1\n");
	my_axis_x_rotation = point_rotation(my_axis_x,-get_yaw*(M_PI/180.0))+carto_center;
	my_axis_y_rotation = point_rotation(my_axis_y,get_yaw*(M_PI/180.0));
	my_axis_y_rotation.y = -my_axis_y_rotation.y;
	my_axis_y_rotation = my_axis_y_rotation + carto_center;
	line(my_map_ch3, carto_center, my_axis_x_rotation, Scalar(0, 0, 255), 2, LINE_AA); // x 빨간색
	line(my_map_ch3, carto_center, my_axis_y_rotation, Scalar(0, 255, 0), 2, LINE_AA); // y 초록색
	printf("rotation x,y : (%f, %f)\n",my_axis_x_rotation.x, my_axis_x_rotation.y);
	printf("rotation x,y : (%f, %f)\n",my_axis_y_rotation.x, my_axis_y_rotation.y);
}

// 맵을 다시 그리는 함수 //
void re_map_function()
{
	if(re_map_count>50)
	{
		my_map = re_map.clone();
		re_map_count = 0;
	}
	else
	{
		printf("map_count : %d\n", re_map_count);
	}

}

// 매트릭스 회전 함수 //
void map_rotation(Mat target_mat)
{
	Mat rotatino_mask = getRotationMatrix2D(carto_center, -get_yaw, 1.0);
	warpAffine(target_mat, my_map_rotation, rotatino_mask, my_map_ch3.size());
}












// 맵 그리는 함수 //
void scanCallback(const sensor_msgs::LaserScan::ConstPtr& scan)
{
	re_map_function(); // 맵을 50번 그렸으면 처음부터 다시 그린다.
	from_cartographer_get_point(); // 함수를 호출해서 my_center를 수정한다.

	// 맵 데이터 획득부분//
	// ydlidar로부터 직접 획득한다. //
	// 전체 데이터 갯수를 획득한다. //
	int count = scan->scan_time / scan->time_increment;

	// count값의 최대치를 직접 ydlidar를 켜서 실험을 통해 구한다.
	// m_a_count 변수의 값을 보고 숫자를 조정한다.
	// 매번 채워져있는 수가 변하므로 함수가 종료되면 삭제되었다가 다시 선언되는것이 좋다.
	double my_array[1000][2];

	// 전체 데이터중 유효한 데이터를 찾는 함수 //
	m_a_count = 0;
	for(int i = 0; i < count; i++)
	{
		float degree = RAD2DEG(scan->angle_min + scan->angle_increment * i);

		if( degree<180 && degree>-180 )
		{
			if( isinf(scan->ranges[i]) || scan->ranges[i]<0.1 || scan->ranges[i]>10 )
			{
			// ydlidar의 datasheet 참조 //
			// 최소 0.1m, 최대 10m의 측정을 보장한다. //
			// 무한대, 0.1m미만, 10m초과 값을 버린다. //
			}
			else
			{
				my_array[m_a_count][0] = degree;
				my_array[m_a_count][1] = scan->ranges[i];

				// openCV로 line을 생성하기 위한 좌표를 계산한다.
				detection.x = my_array[i][1]*cos(my_array[i][0]*M_PI/180.0)*enlarge;
				detection.y = -my_array[i][1]*sin(my_array[i][0]*M_PI/180.0)*enlarge;

				// 회전한 만큼 반대로 회전 시켜준다.
				detection = point_rotation(detection, -get_yaw*(M_PI/180.0));

				detection.x =  carto_center.x + detection.x;
				detection.y =  carto_center.y + detection.y;

				// my_map의 carto_center로부터 detection까지 흰색으로(255), 굵기 2, 라인 안티앨리어싱
				line(my_map, carto_center, detection, Scalar(255), 2, LINE_AA);

				// my_map의 detection위치에 반지름 0.5의 검은색 원
				circle(my_map, detection, 0.5, Scalar(0), 1);
				
				// 어디에 그렸는지 출력
				//printf("angle, distance : [%.3f, %.3f]\n", degree, scan->ranges[i]);
				++m_a_count; 
			}
		}
	}

	// 원본 맵을 보존한다. //
	Mat in[] = {my_map, my_map, my_map};
	merge(in, 3, my_map_ch3);

	// 좌표축은 5번 마다 갱신 //
	if(re_axis_count<5)
	{
		// temp_my_map의 my_center부터 my_axis_x_rotation까지 흰색으로(255), 굵기 2, 라인 안티앨리어싱
		line(my_map_ch3, carto_center, my_axis_x_rotation, Scalar(0, 0, 255), 2, LINE_AA); // x 빨간색
		line(my_map_ch3, carto_center, my_axis_y_rotation, Scalar(0, 255, 0), 2, LINE_AA); // y 초록색
	}
	else
	{
		from_IMU_modify_axis();
		re_axis_count = 0;
		printf("axis reset!\n");
	}

	moveWindow("my_map_window", 100, 100); // 모니터의 좌측 상단이 원점이다. (+x -y)
	namedWindow("my_map_window", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
	imshow("my_map_window", my_map_ch3);

	waitKey(1);
	++re_map_count;
	++re_axis_count;
}




int main(int argc, char **argv)
{
	// ROS 통신을 위한 노드 선언 //
	ros::init(argc, argv, "draw_map_node");
	// 노드 핸들러 선언
	ros::NodeHandle n;

	// 초기 좌표축 x,y 설정 //
	my_axis_x_rotation = my_axis_x + my_center;
	my_axis_y_rotation = my_axis_y;
	my_axis_y_rotation.y = -my_axis_y_rotation.y;
	my_axis_y_rotation = my_axis_y_rotation + my_center;

	// 카토그래퍼에서 보내지는 /scan 토픽을 읽어서 scanCallback함수를 실행한다.
	ros::Subscriber ydlidar_sub = n.subscribe<sensor_msgs::LaserScan>("/scan", 1, scanCallback);
	// degree_publisher.py에서 보내지는 project_degree토픽을 읽어서 get_degree_from_imu함수를 실행한다.
	ros::Subscriber imu_sub = n.subscribe("project_degree", 1, get_degree_from_imu);

	ros::spin();

	return 0;
}
//////////////////////////////////////////////////////////////////////////////////////////////////////////////
