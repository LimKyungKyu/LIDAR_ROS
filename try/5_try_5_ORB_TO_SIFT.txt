
// 맵 1번 그리고 이전맵과 ORB 또는 SURF로 비교하여 특징점 추출하기 //
// 카토그래퍼에서 완전 분리됨 //
// ORB 예제 : https://github.com/gilbutITbook/006939/blob/master/ch14/matching/main.cpp //

#include "ros/ros.h"
#include "sensor_msgs/LaserScan.h"
#include <math.h>
#include <opencv2/opencv.hpp>
#include "tf/transform_listener.h"
#include "project_ros_cpp/get_degree.h"
#define _USE_MATH_DEFINES
#include <cstdio>
#include <iostream>
#include <unistd.h>
#include <std_msgs/Float32.h>
#define RAD2DEG(x) ((x)*180.0/M_PI)


using namespace cv;
using namespace std;


#define my_map_enlarge 15
Mat my_map(40*my_map_enlarge, 40*my_map_enlarge, CV_32FC1, Scalar(0)); // float32형 1채널, 0 = 검은색으로 채운다.
// 중심 (20, 20), 전체 사이즈 40x40, 15배 확대, 1m = 15px //
// 매번 측정하고 유사위치에 더해서 맵을 진하게 만들면서 늘려나갈 계획이다.


Mat re_map(40*my_map_enlarge, 40*my_map_enlarge, CV_32FC1, Scalar(0)); // 초기화를 위한 맵 변수 선언
Mat my_map_ch3; // 3채널 확장을 위한 맵 변수 선언
Mat for_surf_cal_temp; // surf를 위한 공간 선언


// 초기 좌표, 좌표계 선언 //
Point2d my_center(my_map.size().width/2, my_map.size().height/2); // 초기 중심 좌표
Point2d my_axis_x(my_map.size().width/8,0); // x축 좌표계 (폭의 1/8)
Point2d my_axis_y(0,my_map.size().height/8); // y축 좌표계 (길이의 1/8)
Point2d my_axis_x_rotation, my_axis_y_rotation; // IMU 회전 좌표계
int re_axis_count = 0; // 좌표축 갱신을 위한 선언


// 맵 확장을 위한 변수 선언 //
// 중심 (10,10), 전체 사이즈 20x20, 50배 확대, 1m = 50px //
#define assist_enlarge 50
Mat assist_map(20*assist_enlarge, 20*assist_enlarge, CV_32FC1, Scalar(0));
Mat assist_re_map(20*assist_enlarge, 20*assist_enlarge, CV_32FC1, Scalar(0));
Mat assist_map_sum(20*assist_enlarge, 20*assist_enlarge, CV_32FC1, Scalar(0));
Point2d assist_center(assist_map.size().width/2, assist_map.size().height/2);
Point2d assist_axis_x(assist_map.size().width/8,0);
Point2d assist_axis_y(0,assist_map.size().height/8); 
Point2d assist_x_rotation, assist_y_rotation;


// 데이터 저장공간 선언 //
Point2d detection; // 유효한 좌표의 저장을 위한 변수 선언
Point2d assist_detection; // 이하 동일


// IMU값을 위한 변수 선언 //
float get_roll = 0.0;
float get_pitch = 0.0;
float get_yaw = 0.0;
float imu_time_check = 0.0;

// 10번마다 축적 맵을 보여주기 위한 카운트 //
int accumulate_map_count = 0;


// IMU에서 각도를 받는 함수 //
void get_degree_from_imu(const project_ros_cpp::get_degree::ConstPtr& msg)
{
	// msg에서 data를 꺼낸다.
	// degree, 즉 0 ~ 360의 값을 준다.
	get_roll = msg->roll;
	get_pitch = msg->pitch;
	get_yaw = msg->yaw;
	//printf("get degree : %f, %f, %f\n", get_roll, get_pitch, get_yaw);
	imu_time_check = msg->imu_time_stamp; // 보낸 시점의 시간을 알아낸다.
}


// scan데이터와 IMU의 전송시점 비교를 위한 함수 //
double scan_time_check = 0.0;
void check_scan_stamp(const std_msgs::Float32::ConstPtr& msg)
{
	scan_time_check = msg->data;
}


// 포인트 회전을 위한 함수 //
Point2d point_rotation(Point2d a, float b)
{
	// float b 는 라디안이 입력되야한다.

	Point2d temp_a(a.x,a.y);

	temp_a.x = a.x*cos(b) - a.y*sin(b);
	temp_a.y = a.x*sin(b) + a.y*cos(b);

	//std::cout<<temp_a.x<<" "<<temp_a.y<< std::endl;
	return temp_a;
}


// 좌표축 회전을 위한 함수 //
void from_IMU_modify_axis()
{
	//printf("\nhere? Tag1\n");
	my_axis_x_rotation = point_rotation(my_axis_x,-get_yaw*(M_PI/180.0))+my_center;
	my_axis_y_rotation = point_rotation(my_axis_y,get_yaw*(M_PI/180.0));
	my_axis_y_rotation.y = -my_axis_y_rotation.y;
	my_axis_y_rotation = my_axis_y_rotation+my_center;
	line(my_map_ch3, my_center, my_axis_x_rotation, Scalar(0, 0, 1), 2, LINE_AA); // x 빨간색
	line(my_map_ch3, my_center, my_axis_y_rotation, Scalar(0, 1, 0), 2, LINE_AA); // y 초록색
	//printf("rotation x,y : (%f, %f)\n",my_axis_x_rotation.x, my_axis_x_rotation.y);
	//printf("rotation x,y : (%f, %f)\n",my_axis_y_rotation.x, my_axis_y_rotation.y);
}


// 특징점 추출을 위한 함수 //
void find_homography(Mat for_surf_1, Mat for_surf_2)
{
	Mat src1 = for_surf_1;
	Mat src2 = for_surf_2;

	//printf("\nhere? Tag1\n");

	if (src1.empty() || src2.empty()) {
		cerr << "Image load failed!" << endl;
		return;
	}

	//printf("\nhere? Tag2\n");
	Ptr<Feature2D> feature = ORB::create();

	vector<KeyPoint> keypoints1, keypoints2;
	Mat desc1, desc2;
	feature->detectAndCompute(src1, Mat(), keypoints1, desc1);
	feature->detectAndCompute(src2, Mat(), keypoints2, desc2);

	Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_HAMMING);

	vector<DMatch> matches;
	matcher->match(desc1, desc2, matches);

	std::sort(matches.begin(), matches.end());
	vector<DMatch> good_matches(matches.begin(), matches.begin() + 50);

	Mat dst;
	drawMatches(src1, keypoints1, src2, keypoints2, good_matches, dst,
		Scalar::all(-1), Scalar::all(-1), vector<char>(),
		DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);

	vector<Point2f> pts1, pts2;
	for (size_t i = 0; i < good_matches.size(); i++) {
		pts1.push_back(keypoints1[good_matches[i].queryIdx].pt);
		pts2.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}

	moveWindow("dst", 700, 100); // 모니터의 좌측 상단이 원점이다. (+x -y)
	namedWindow("dst", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
	imshow("dst", dst);
	waitKey(1);
}

// 맵 그리는 함수 //
void scanCallback(const sensor_msgs::LaserScan::ConstPtr& scan)
{

	// 맵 갱신 //
	my_map = re_map.clone();
	assist_map = assist_re_map.clone();

	// ydlidar_node가 발생시킨 scan토픽으로부터 전체 데이터 갯수를 획득 //
	int count = scan->scan_time / scan->time_increment;

	// my_array는 m_a_count 변수의 값을 보고 조정한다. //
	// 매번 수가 변하므로 사용 후 파기하고 다시 선언하는것이 좋다. //
	double my_array[1000][2];

	// 전체 데이터중 유효한 데이터를 찾는 부분 //
	int m_a_count = 0; // 유효한 거리값 측정 위한 선언
	for(int i = 0; i < count; i++)
	{
		float degree = RAD2DEG(scan->angle_min + scan->angle_increment * i);

		if( degree<180.0 && degree>-180.0 )
		{
			if( isinf(scan->ranges[i]) || scan->ranges[i]<0.1 || scan->ranges[i]>8.0 )
			{
			// ydlidar의 datasheet 참조 //
			// 최소 0.1m, 최대 8m의 측정을 보장한다. //
			// 무한대, 0.1m미만, 8m초과 값을 버린다. //
			}
			else
			{
				my_array[m_a_count][0] = degree;
				my_array[m_a_count][1] = scan->ranges[i];
				//printf("check 1\n");
				// openCV로 line을 생성하기 위한 좌표를 계산하고 확대 시킨다. //
				detection.x = my_array[m_a_count][1]*cos(my_array[m_a_count][0]*M_PI/180.0)*my_map_enlarge;
				detection.y = -my_array[m_a_count][1]*sin(my_array[m_a_count][0]*M_PI/180.0)*my_map_enlarge;
				assist_detection.x = my_array[m_a_count][1]*cos(my_array[m_a_count][0]*M_PI/180.0)*assist_enlarge;
				assist_detection.y = -my_array[m_a_count][1]*sin(my_array[m_a_count][0]*M_PI/180.0)*assist_enlarge;
				//printf("check 2\n");
				// 회전한 만큼 반대로 회전 시켜준다. //
				detection = point_rotation(detection, -get_yaw*(M_PI/180.0));
				assist_detection = point_rotation(assist_detection, -get_yaw*(M_PI/180.0));
				//printf("check 3\n");
				// 맵의 중심으로 이동시킨다. //
				detection.x =  my_center.x + detection.x;
				detection.y =  my_center.y + detection.y;
				assist_detection.x =  assist_center.x + assist_detection.x;
				assist_detection.y =  assist_center.y + assist_detection.y;
				//printf("check 4\n");
				// my_map의 my_center로 부터 detection까지 흰색으로(1), 굵기 2
				line(my_map, my_center, detection, Scalar(1.0), 2);
				line(assist_map, assist_center, assist_detection, Scalar(0.01), 5);
				//printf("check 5\n");
				// my_map의 detection위치에 반지름 2의 검은색 원, 굵기 -1 (채움)
				circle(my_map, detection, 2, Scalar(0.0), -1);
				circle(assist_map, assist_detection, 3, Scalar(-0.02), -1);
				//printf("check 6\n");
				++m_a_count;

				//printf("angle, distance : [%.3f, %.3f]\n", degree, scan->ranges[i]);
				//printf("i use yaw %f\n", get_yaw);
				//printf("this time m_a_count is %d\n",m_a_count);
			}
		}
	}

	if ( m_a_count == 0 )
	{
	}
	else
	{
		// 특징점 매칭을 위해 Mat 형 변환 //
		if ( for_surf_cal_temp.total() == 0 )
		{
			Mat for_surf;
			my_map.convertTo(for_surf, CV_8UC1, 255, 0);
			vector<uchar> for_jpg_buff;
			vector<int> param = vector<int>(2);
			param[0]=CV_IMWRITE_JPEG_QUALITY;
			param[1]=95;
			imencode(".jpg",for_surf,for_jpg_buff,param);
			Mat for_surf_cal = imdecode(Mat(for_jpg_buff),CV_LOAD_IMAGE_GRAYSCALE);
			for_surf_cal_temp = for_surf_cal;
		}
		else
		{
			Mat for_surf;
			my_map.convertTo(for_surf, CV_8UC1, 255, 0);
			vector<uchar> for_jpg_buff;
			vector<int> param = vector<int>(2);
			param[0]=CV_IMWRITE_JPEG_QUALITY;
			param[1]=95;
			imencode(".jpg",for_surf,for_jpg_buff,param);
			Mat for_surf_cal = imdecode(Mat(for_jpg_buff),CV_LOAD_IMAGE_GRAYSCALE);
			try{
			    find_homography(for_surf_cal,for_surf_cal_temp);
			}
			catch(cv::Exception& e){
			     printf("can't homography\n");
			} 
			for_surf_cal_temp = for_surf_cal;
		}


		// 색이 있는 좌표축을 그리기 위해 원본 맵을 3채널로 확장한다. //
		Mat in[] = {my_map, my_map, my_map};
		merge(in, 3, my_map_ch3);
		// 참고 : convertTo를 사용하여 변환하는 경우 검은색만 나오는 에러 발생 //
		// my_map.convertTo(my_map_ch3, CV_8UC3, 255.0); //


		// 좌표축 갱신 부분 //
		from_IMU_modify_axis();

		moveWindow("my_map_window", 100, 100); // 모니터의 좌측 상단이 원점이다. (+x -y)
		namedWindow("my_map_window", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
		imshow("my_map_window", my_map_ch3);

		assist_map_sum = assist_map_sum + assist_map;
		waitKey(1);

		++accumulate_map_count;
		if ( accumulate_map_count > 9)
		{
			moveWindow("assist_window", 400, 100); // 모니터의 좌측 상단이 원점이다. (+x -y)
			namedWindow("assist_window", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
			waitKey(1);
			imshow("assist_window", assist_map_sum);
		}
	} 


}


int main(int argc, char **argv)
{

	ros::init(argc, argv, "draw_map_node"); // ROS 통신을 위한 노드 선언
	ros::NodeHandle n; // 노드 핸들러 선언

	// 전체 맵 좌표축 x,y 설정 //
	my_axis_x_rotation = my_axis_x + my_center;
	my_axis_y_rotation = my_axis_y;
	my_axis_y_rotation.y = -my_axis_y_rotation.y;
	my_axis_y_rotation = my_axis_y_rotation + my_center;

	// 보조 맵 좌표축 x,y 설정 //
	assist_x_rotation = assist_axis_x + assist_center;
	assist_y_rotation = assist_axis_y;
	assist_y_rotation.y = -assist_y_rotation.y;
	assist_y_rotation = assist_y_rotation + assist_center;


	ros::Subscriber imu_sub = n.subscribe("project_degree", 1, get_degree_from_imu);
	// degree_publisher.py에서 보내지는 project_degree 토픽을 읽어서 get_degree_from_imu함수를 실행한다.

	ros::Subscriber ydlidar_sub = n.subscribe<sensor_msgs::LaserScan>("/scan", 1, scanCallback);
	// ydlidar_node에서 보내지는 /scan 토픽을 읽어서 scanCallback함수를 실행한다. //
	ros::Subscriber scan_time_sub = n.subscribe("scan_pub_time_for_imu", 1, check_scan_stamp);
	// ydlidar의 scan값과 imu의 동기화를 위해서 함수를 실행한다.

	ros::spin();
	// spin에 의해서 위의 두 노드가 While처럼 무한 루프로 토픽이 들어올때마다 함수를 실행한다. //

	return 0;
}
//////////////////////////////////////////////////////////////////////////////////////////////////////////////

IMU와 시간연동을 하기 위한 시도
// 시도 1 (필요없는 값이였음) //
// #include "std_msgs/Header.h" //
//ros::Time get_scan_time = scan->header.stamp;
//float scan_time_check = get_scan_time.sec;
//printf("scan time : %f\n", scan_time_check);


// 시도 2 (필요없는 값이였음) //
// #include "std_msgs/Header.h" //
//float scan_time_check = scan.scan_time;
//printf("scan time : %f\n", scan_time_check);


// 시도 3 (성공) //
ydlidar_node.cpp에 아래 헤더 추가 
#include <std_msgs/Float32.h>
#include <unistd.h>
#include <stdio.h>
#include <time.h>

ros::Publisher scan_pub = nh.advertise<sensor_msgs::LaserScan>("scan", 1); 큐를 1로 수정하고 아랫줄에 아래 내용을 입력
	ros::Publisher scan_time_pub = nh.advertise<std_msgs::Float32>("scan_pub_time_for_imu", 1); 

scan_pub.publish(scan_msg); 윗줄에 아래 내용을 입력
	std_msgs::Float32 scan_time_for_imu;
	struct timespec spec;
	clock_gettime(CLOCK_MONOTONIC, &spec); // CLOCK_MONOTONIC : 컴퓨터가 켜진 시점부터 지난 시각
	float stamp_seconds = spec.tv_sec;
	float stamp_nanoseconds = spec.tv_nsec;
	float stamp_sum = stamp_seconds+stamp_nanoseconds/1000000000;	
	scan_time_for_imu.data = stamp_sum;
	scan_time_pub.publish(scan_time_for_imu);

ydlidar_node가 존재하는 폴더에서 catkin_make 수행

// 파이썬 //
cd && cd Project_ROS_nano/src/project_ros_python/src && vi degree_publisher.py
publish 하기 전에 for_pub.imu_time_stamp = float(time.clock_gettime(time.CLOCK_MONOTONIC)) 한줄 추가
msg파일(파이썬,cpp 모두) float32 imu_time_stamp 추가

