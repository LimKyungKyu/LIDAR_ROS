//////////////////////////////////////////////////////////////////////////////////////////////////////////////
// 1. 3번마다 remap //
// 카토그래퍼의 좌표기능 사용하지 않음 //
#include "ros/ros.h"
#include "sensor_msgs/LaserScan.h"
#include <math.h>
#include <opencv2/opencv.hpp>
#include "tf/transform_listener.h"
#include "project_ros_cpp/get_degree.h"
#define _USE_MATH_DEFINES
#include <cstdio>
#include <iostream>
#include <unistd.h>
#define RAD2DEG(x) ((x)*180.0/M_PI)


using namespace cv;
using namespace std;


// 초기 맵 세팅 //
// 중심 (20, 20), 전체 사이즈 40x40 //
// 확대 15배, 1m = 15px, #define enlarge 15 //
// 확대 후, 상하좌우 검은색 패딩(확대 후 매트릭스의 상하좌우 여백), #define padding 0 //
// 1픽셀 = 1m, 15배 확대햇으면 15픽셀 = 1m 이다.
#define enlarge 15
#define padding 0
Mat my_map(40*enlarge, 40*enlarge, CV_32FC1, Scalar(0)); // 40x40을 15배확대, float32형 3채널, 0 = 검은색으로 채운다.
Mat re_map(40*enlarge, 40*enlarge, CV_32FC1, Scalar(0)); // 초기화를 위한 맵 변수 선언
Mat my_map_ch3; // 3채널 확장을 위한 공간 선언
int re_map_count = 0; // 맵 초기화 카운트를 위한 변수 선언

// 초기 좌표, 좌표계 선언 //
Point2d my_center(my_map.size().width/2, my_map.size().height/2); // 초기 중심 좌표
Point2d my_axis_x(my_map.size().width/8,0); // x축 좌표계 (폭의 1/8)
Point2d my_axis_y(0,my_map.size().height/8); // y축 좌표계 (길이의 1/8)
Point2d my_axis_x_rotation, my_axis_y_rotation; // IMU 회전 좌표계
int re_axis_count = 0; // 좌표축 갱신을 위한 선언

// 데이터 저장공간 선언 //
int m_a_count = 0; // 유효한 거리값 개수 확인을 위한 선언
Point2d detection; // 유효한 좌표저장을 위한 변수 선언

// IMU각도 저장을 위한 변수 선언 
float get_roll = 0.0;
float get_pitch = 0.0;
float get_yaw = 0.0;
float momentary_yaw = 0.0;


// IMU에서 각도를 받는 함수 //
void get_degree_from_imu(const project_ros_cpp::get_degree::ConstPtr& msg)
{
	// msg에서 data를 꺼낸다.
	// degree로 주어진다.
	// 0 ~ 360의 값을 준다.
	get_roll = msg->roll;
	get_pitch = msg->pitch;
	get_yaw = msg->yaw;
	//printf("get degree : %f, %f, %f\n", get_roll, get_pitch, get_yaw);
}


// 포인트 회전을 위한 함수 //
Point2d point_rotation(Point2d a, float b)
{
	// float b 는 라디안이 입력되야한다.

	Point2d temp_a(a.x,a.y);

	temp_a.x = a.x*cos(b) - a.y*sin(b);
	temp_a.y = a.x*sin(b) + a.y*cos(b);

	//std::cout<<temp_a.x<<" "<<temp_a.y<< std::endl;
	return temp_a;
}


// 좌표축 회전을 위한 함수 //
void from_IMU_modify_axis()
{
	//printf("\nhere? Tag1\n");
	my_axis_x_rotation = point_rotation(my_axis_x,-momentary_yaw*(M_PI/180.0))+my_center;
	my_axis_y_rotation = point_rotation(my_axis_y,momentary_yaw*(M_PI/180.0));
	my_axis_y_rotation.y = -my_axis_y_rotation.y;
	my_axis_y_rotation = my_axis_y_rotation+my_center;
	line(my_map_ch3, my_center, my_axis_x_rotation, Scalar(0, 0, 1), 2, LINE_AA); // x 빨간색
	line(my_map_ch3, my_center, my_axis_y_rotation, Scalar(0, 1, 0), 2, LINE_AA); // y 초록색
	printf("rotation x,y : (%f, %f)\n",my_axis_x_rotation.x, my_axis_x_rotation.y);
	printf("rotation x,y : (%f, %f)\n",my_axis_y_rotation.x, my_axis_y_rotation.y);
}


// 맵 그리는 함수 //
void scanCallback(const sensor_msgs::LaserScan::ConstPtr& scan)
{
	
	momentary_yaw = get_yaw;

	// 맵 갱신 부분//
	if(re_map_count>3)
	{
		my_map = re_map.clone();
		re_map_count = 0;
	}
	else
	{
		printf("map_count : %d\n", re_map_count);
	}


	// 맵 데이터 획득 부분//
	int count = scan->scan_time / scan->time_increment;
	// ydlidar_node가 발생시킨 scan토픽으로부터 전체 데이터 갯수를 획득한다. //

	double my_array[1000][2];
	// count값의 최대치는 m_a_count 변수의 값을 보고 조정한다. //
	// 매번 수가 변하므로 매번 다시 선언하는것이 좋다. //


	// 전체 데이터중 유효한 데이터를 찾는 부분 //
	m_a_count = 0;
	for(int i = 0; i < count; i++)
	{
		float degree = RAD2DEG(scan->angle_min + scan->angle_increment * i);

		if( degree<180.0 && degree>-180.0 )
		{
			if( isinf(scan->ranges[i]) || scan->ranges[i]<0.1 || scan->ranges[i]>10 )
			{
			// ydlidar의 datasheet 참조 //
			// 최소 0.1m, 최대 10m의 측정을 보장한다. //
			// 무한대, 0.1m미만, 10m초과 값을 버린다. //
			}
			else
			{
				my_array[m_a_count][0] = degree + 180.0 ;
				my_array[m_a_count][1] = scan->ranges[i];

				// openCV로 line을 생성하기 위한 좌표를 계산한다.
				detection.x = my_array[i][1]*cos(my_array[i][0]*M_PI/180.0)*enlarge;
				detection.y = -my_array[i][1]*sin(my_array[i][0]*M_PI/180.0)*enlarge;

				// 회전한 만큼 반대로 회전 시켜준다.
				detection = point_rotation(detection, -momentary_yaw*(M_PI/180.0));

				detection.x =  my_center.x + detection.x;
				detection.y =  my_center.y + detection.y;

				// my_map의 my_center로 부터 detection까지 흰색으로(1), 굵기 2, 라인 안티앨리어싱
				line(my_map, my_center, detection, Scalar(1), 2, LINE_AA);

				// my_map의 detection위치에 반지름 0.5의 검은색 원
				circle(my_map, detection, 0.5, Scalar(0), 1);
				
				++m_a_count;

				//printf("angle, distance : [%.3f, %.3f]\n", degree, scan->ranges[i]);
				//printf("i use yaw %f\n",momentary_yaw);
				//printf("this time m_a_count is %d\n",m_a_count);
			}
		}
	}

	// 원본 맵을 3채널로 확장한다. //
	Mat in[] = {my_map, my_map, my_map};
	merge(in, 3, my_map_ch3);

	// my_map.convertTo(my_map_ch3, CV_8UC3, 255.0); //
	// 이렇게 변환하는 경우 검은색만 나오는 에러 발생 //

	// 좌표축은 3번 마다 갱신 //
	if(re_axis_count<4)
	{
		// my_map_ch3의 my_center로 부터 my_axis_x_rotation까지 빨간색으로(0, 0, 1), 굵기 2, 라인 안티앨리어싱
		line(my_map_ch3, my_center, my_axis_x_rotation, Scalar(0, 0, 1), 2, LINE_AA); // x 빨간색
		line(my_map_ch3, my_center, my_axis_y_rotation, Scalar(0, 1, 0), 2, LINE_AA); // y 초록색
	}
	else
	{
		from_IMU_modify_axis();
		re_axis_count = 0;
		printf("axis reset!\n");
	}

	moveWindow("my_map_window", 100, 100); // 모니터의 좌측 상단이 원점이다. (+x -y)
	namedWindow("my_map_window", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
	imshow("my_map_window", my_map_ch3);

	waitKey(1);
	++re_map_count;
	++re_axis_count;
	//sleep (1);
}


int main(int argc, char **argv)
{

	// ROS 통신을 위한 노드 선언 //
	ros::init(argc, argv, "draw_map_node");
	// 노드 핸들러 선언
	ros::NodeHandle n;

	// 초기 좌표축 x,y 설정 //
	my_axis_x_rotation = my_axis_x + my_center;
	my_axis_y_rotation = my_axis_y;
	my_axis_y_rotation.y = -my_axis_y_rotation.y;
	my_axis_y_rotation = my_axis_y_rotation + my_center;

	// spin에 의해서 노드가 항상 켜지게 되고, 토픽이 들어오면 함수를 실행한다. //
	ros::Subscriber ydlidar_sub = n.subscribe<sensor_msgs::LaserScan>("/scan", 1, scanCallback);
	// ydlidar_node에서 보내지는 /scan 토픽을 읽어서 scanCallback함수를 실행한다.
	ros::Subscriber imu_sub = n.subscribe("project_degree", 1, get_degree_from_imu);
	// degree_publisher.py에서 보내지는 project_degree 토픽을 읽어서 get_degree_from_imu함수를 실행한다.
	ros::spin();

	return 0;
}
//////////////////////////////////////////////////////////////////////////////////////////////////////////////
roscore
rosrun ydlidar ydlidar_node
rosrun project_ros_python degree_publisher
rosrun project_ros_cpp lidar_make_map
// 런치 파일 //
<launch>

  <node pkg="ydlidar" type="ydlidar_node" name="ydlidar_node"/>
  <node pkg="project_ros_python" type="degree_publisher.py" name="degree_publisher"/>
  <node pkg="project_ros_cpp" type="lidar_make_map" name="lidar_make_map" output="screen"/>

</launch>









































































//////////////////////////////////////////////////////////////////////////////////////////////////////////////
// 2. SURF 실행해보기 //
// ORB 예제를 응용하기 : https://github.com/gilbutITbook/006939/blob/master/ch14/matching/main.cpp //
#include "opencv2/opencv.hpp"
#include <iostream>

using namespace cv;
using namespace std;

void find_homography()
{
	Mat src1 = imread("box.png", IMREAD_GRAYSCALE);
	Mat src2 = imread("box_in_scene.png", IMREAD_GRAYSCALE);

	if (src1.empty() || src2.empty()) {
		cerr << "Image load failed!" << endl;
		return;
	}

	Ptr<Feature2D> feature = ORB::create();

	vector<KeyPoint> keypoints1, keypoints2;
	Mat desc1, desc2;
	feature->detectAndCompute(src1, Mat(), keypoints1, desc1);
	feature->detectAndCompute(src2, Mat(), keypoints2, desc2);

	Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_HAMMING);

	vector<DMatch> matches;
	matcher->match(desc1, desc2, matches);

	std::sort(matches.begin(), matches.end());
	vector<DMatch> good_matches(matches.begin(), matches.begin() + 50);

	Mat dst;
	drawMatches(src1, keypoints1, src2, keypoints2, good_matches, dst,
		Scalar::all(-1), Scalar::all(-1), vector<char>(),
		DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);

	vector<Point2f> pts1, pts2;
	for (size_t i = 0; i < good_matches.size(); i++) {
		pts1.push_back(keypoints1[good_matches[i].queryIdx].pt);
		pts2.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}

	Mat H = findHomography(pts1, pts2, RANSAC);

	vector<Point2f> corners1, corners2;
	corners1.push_back(Point2f(0, 0));
	corners1.push_back(Point2f(src1.cols - 1.f, 0));
	corners1.push_back(Point2f(src1.cols - 1.f, src1.rows - 1.f));
	corners1.push_back(Point2f(0, src1.rows - 1.f));
	perspectiveTransform(corners1, corners2, H);

	vector<Point> corners_dst;
	for (Point2f pt : corners2) {
		corners_dst.push_back(Point(cvRound(pt.x + src1.cols), cvRound(pt.y)));
	}

	polylines(dst, corners_dst, true, Scalar(0, 255, 0), 2, LINE_AA);

	imshow("dst", dst);

	waitKey(1);
}

int main(void)
{
	find_homography();
	return 0;
}
//////////////////////////////////////////////////////////////////////////////////////////////////////////////
// CMakeLists.txt //
cmake_minimum_required(VERSION 2.8)
project(matching)
find_package(OpenCV REQUIRED)
include_directories(${OpenCV_INCLUDE_DIRS})
add_executable(matching main.cpp)
target_link_libraries(matching ${OpenCV_LIBS})
// CMakeLists.txt가 있는 폴더에서 터미널 키고 // 
cmake CMakeLists.txt && make
// 아래 이미지 다운로드 //
https://github.com/gilbutITbook/006939/blob/master/ch14/matching/box.png
https://github.com/gilbutITbook/006939/blob/master/ch14/matching/box_in_scene.png
./matching 실행
