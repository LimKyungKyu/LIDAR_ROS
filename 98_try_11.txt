// 맵 1번 그리고 이전맵과 ORB, SIFT, SURF로 비교하여 특징점 추출하기 //
// 카토그래퍼에서 완전 분리됨 //
// ORB 예제 : https://github.com/gilbutITbook/006939/blob/master/ch14/matching/main.cpp //

#include "ros/ros.h"
#include "sensor_msgs/LaserScan.h"
#include <math.h>
#include <opencv2/opencv.hpp>
#include "tf/transform_listener.h"
#include "project_ros_cpp/get_degree.h"
#define _USE_MATH_DEFINES
#include <cstdio>
#include <iostream>
#include <unistd.h>
#include <std_msgs/Float32.h>
// #include <opencv4/opencv2/xfeatures2d/nonfree.hpp>
#define RAD2DEG(x) ((x)*180.0/M_PI)

using namespace cv;
using namespace std;

// 맵을 위한 변수 선언 //
// 중심 (10,10), 전체 사이즈 20x20, 50배 확대, 1m = 50px //
#define assist_enlarge 50
Mat assist_map(20*assist_enlarge, 20*assist_enlarge, CV_8UC1, Scalar(100));

Mat assist_re_map(20*assist_enlarge, 20*assist_enlarge, CV_8UC1, Scalar(100));
Point2d assist_center(assist_map.size().width/2, assist_map.size().height/2);
Point2d assist_axis_x(assist_map.size().width/8,0);
Point2d assist_axis_y(0,assist_map.size().height/8); 
Point2d assist_x_rotation, assist_y_rotation;

// surf를 위한 변수 선언 //
Mat temp_5;
Mat orb_sift_surf_area;
Point2d rot_cen_for_homo;

// 데이터 저장공간 선언 //
Point2d assist_detection;

// IMU값을 위한 변수 선언 //
float get_roll = 0.0;
float get_pitch = 0.0;
float get_yaw = 0.0;
float imu_time_check = 0.0;

// 맵 갱신을 위한 변수 선언 //
int remap_count = 0;

// 맵 축적을 위한 조건 //
int acu_map_condition;

// IMU에서 각도를 받는 함수 //
void get_degree_from_imu(const project_ros_cpp::get_degree::ConstPtr& msg)
{
	// msg에서 data를 꺼낸다.
	// degree, 즉 0 ~ 360의 값을 준다.
	get_roll = msg->roll;
	get_pitch = msg->pitch;
	get_yaw = msg->yaw;
	//printf("get degree : %f, %f, %f\n", get_roll, get_pitch, get_yaw);
	imu_time_check = msg->imu_time_stamp; // 보낸 시점의 시간을 알아낸다.
}

// scan데이터와 IMU의 전송시점 비교를 위한 함수 //
double scan_time_check = 0.0;
void check_scan_stamp(const std_msgs::Float32::ConstPtr& msg)
{
	scan_time_check = msg->data;
}

// 포인트 회전을 위한 함수 //
Point2d point_rotation(Point2d a, float b)
{
	// float b 는 라디안이 입력되야한다.

	Point2d temp_a;

	temp_a.x = a.x*cos(b) - a.y*sin(b);
	temp_a.y = a.x*sin(b) + a.y*cos(b);

	//std::cout<<temp_a.x<<" "<<temp_a.y<< std::endl;
	return temp_a;
}

// Mat 이동 함수 //
// 좌측 상단으로부터 +x -y 방향으로 1,1 움직이는것 확인함 //
void mat_translation(Mat img, Mat dst, Point2d pt)
{
	// img를 pt만큼 이동시켜서 dst에 넣는다.
	Rect rect(Point(0,0), img.size()); // 0,0부터 img.size() 까지 그린다.
	for (int i=0; i<dst.rows; i++)
	{
		for (int j=0; j<dst.cols; j++)
		{
			Point2d dst_pt(j,i);
			Point2d img_pt = dst_pt - pt;
			if (rect.contains(img_pt))
				dst.at<uchar>(dst_pt) = img.at<uchar>(img_pt);
		}
	}
}

void accumulation_mat(Mat for_surf_1, Mat for_surf_2)
{
	Mat src1 = for_surf_1.clone(); // 새로운 맵
	Mat src2 = for_surf_2.clone(); // 원본 맵

	if (src1.empty() || src2.empty())
	{
		cerr << "Image load failed!" << endl;
		return;
	}
	Ptr<Feature2D> feature = ORB::create();
	// Ptr<Feature2D> feature = xfeatures2d::SURF::create();
	vector<KeyPoint> keypoints1, keypoints2;
	Mat desc1, desc2;
	feature->detectAndCompute(src1, Mat(), keypoints1, desc1);
	feature->detectAndCompute(src2, Mat(), keypoints2, desc2);
	Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_HAMMING);
	// Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_L1);
	vector<DMatch> matches;
	matcher->match(desc1, desc2, matches);
	std::sort(matches.begin(), matches.end());
	vector<DMatch> good_matches(matches.begin(), matches.begin() + 5);
	vector<Point2f> pts1, pts2;
	for (size_t i = 0; i < good_matches.size(); i++)
	{
		pts1.push_back(keypoints1[good_matches[i].queryIdx].pt);
		pts2.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}


	// 이미지 2개의 특징점 5개로 두점사이의 거리를 구해서 정수화 한다.
	vector<int> xy_distance;
	xy_distance.reserve(6);
	for ( int i=0; i<good_matches.size(); i++ )
	{
		xy_distance.push_back(pow((pow((pts1[i].x-pts2[i].x),2)+pow((pts1[i].y-pts2[i].y),2)), 0.5));
		//printf("xy_distance : %d\n", xy_distance[i]);
	}

	// 얻어낸 정수가 일정하면 이미지가 일치한것이므로 해당 정수의 빈도를 구한다.
	int max_distance = pow( (pow(for_surf_1.size().width,2)+pow(for_surf_1.size().height,2)), 0.5 ); // 대각선길이 = 얻을 수 있는 정수의 최대값
	int repeat_check[max_distance] = {0};
	for ( int i=0; i<good_matches.size(); i++ )
	{
		repeat_check[xy_distance[i]] += 1;
	}

	// 최대 빈도수를 얻는다.
	int accumulation_check = *max_element(repeat_check, repeat_check+max_distance); // 최대 빈도수 
	//printf("accumulation_check : %d\n", accumulation_check);

	// 최대 빈도수가 70%를 초과하면 아래 작업을 수행한다.
	acu_map_condition = int(good_matches.size()*0.7);
	if ( accumulation_check > acu_map_condition )
	{
		// 최대 빈도수에 해당하는 정수를 얻는다.
		int get_move_distance = 0;
		for ( int i=0; i<max_distance; i++ )
		{
			if ( accumulation_check == repeat_check[i] )
			{
				get_move_distance = i;
				//printf("get_move_distance : %d\n", i);
				// 정수가 일치하는 점의 x,y를 구해서 이동시키고 맵에 누적한다.
				for ( int j=0; j<good_matches.size(); j++ )
				{
					if ( xy_distance[j] == get_move_distance )
					{
						double x_move = pts2[j].x - pts1[j].x;
						double y_move = pts2[j].y - pts1[j].y;

						Mat accumulation_ready= Mat(src1.size(), src1.type(), Scalar(100));
						mat_translation(src1, accumulation_ready, Point2d(x_move,y_move));

						vector<uchar> for_jpg_buff;
						vector<int> param = vector<int>(2);
						param[0]=CV_IMWRITE_JPEG_QUALITY;
						param[1]=95;
						imencode(".jpg",accumulation_ready,for_jpg_buff,param);
						Mat for_surf_cal = imdecode(Mat(for_jpg_buff),CV_LOAD_IMAGE_GRAYSCALE);

						for (int i = 0; i < for_surf_cal.rows; i++)
						{
							for (int j = 0; j < for_surf_cal.cols; j++)
							{
								if ( for_surf_cal.at<uchar>(i, j) < 200) 
								{
									for_surf_cal.at<uchar>(i, j) = 0;
								}
							}
						}

						orb_sift_surf_area = orb_sift_surf_area + for_surf_cal;
						printf("finally accumulation (x,y) : %f,%f\n", x_move, y_move);
						return;
					}
				}
			}
		}
	}
}


void homography_final(Mat for_surf_1, Mat for_surf_2)
{
	Mat src1 = for_surf_1.clone(); // 새로운 맵
	Mat src2 = for_surf_2.clone(); // 원본 맵

	if (src1.empty() || src2.empty()) {
		cerr << "Image load failed!" << endl;
		return;
	}

	Ptr<Feature2D> feature = ORB::create();
	// Ptr<Feature2D> feature = xfeatures2d::SURF::create();
	vector<KeyPoint> keypoints1, keypoints2;
	Mat desc1, desc2;
	feature->detectAndCompute(src1, Mat(), keypoints1, desc1);
	feature->detectAndCompute(src2, Mat(), keypoints2, desc2);
	Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_HAMMING);
	// Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_L1);
	vector<DMatch> matches;
	matcher->match(desc1, desc2, matches);
	std::sort(matches.begin(), matches.end());
	vector<DMatch> good_matches(matches.begin(), matches.begin() + 5);
	vector<Point2f> pts1, pts2;
	for (size_t i = 0; i < good_matches.size(); i++)
	{
		pts1.push_back(keypoints1[good_matches[i].queryIdx].pt);
		pts2.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}

	rot_cen_for_homo.x = src1.size().width/2;
	rot_cen_for_homo.y = src1.size().height/2;

	vector<double> original_degree, temp_degree;
	for (int i=0; i<good_matches.size(); i++)
	{
		original_degree.push_back(atan2( -(pts2[i].y-rot_cen_for_homo.y), (pts2[i].x-rot_cen_for_homo.x) ));
		temp_degree.push_back(atan2( -(pts1[i].y-rot_cen_for_homo.y), (pts1[i].x-rot_cen_for_homo.x)));
	}

	// 반시계 + 
	Mat rot_mask_1 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[0]-temp_degree[0])*180.0/M_PI , 1);
	Mat rot_mask_2 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[1]-temp_degree[1])*180.0/M_PI , 1);
	Mat rot_mask_3 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[2]-temp_degree[2])*180.0/M_PI , 1);
	Mat rot_mask_4 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[3]-temp_degree[3])*180.0/M_PI , 1);
	Mat rot_mask_5 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[4]-temp_degree[4])*180.0/M_PI , 1);

	// src1을 rot_map_rank_1에 담는다. temp_rot_1를 참조해서, 사이즈, 타입.
	Mat rot_map_temp_1, rot_map_temp_2, rot_map_temp_3, rot_map_temp_4, rot_map_temp_5;
	warpAffine(src1, rot_map_temp_1, rot_mask_1, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_2, rot_mask_2, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_3, rot_mask_3, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_4, rot_mask_4, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_5, rot_mask_5, src1.size(), INTER_LINEAR);

	Mat rot_map_1 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_1(rot_map_1, Rect(Point(0,0), rot_map_1.size()));
	rot_map_temp_1.copyTo(imageROI_1,rot_map_temp_1);

	Mat rot_map_2 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_2(rot_map_2, Rect(Point(0,0), rot_map_2.size()));
	rot_map_temp_2.copyTo(imageROI_2,rot_map_temp_2);

	Mat rot_map_3 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_3(rot_map_3, Rect(Point(0,0), rot_map_3.size()));
	rot_map_temp_3.copyTo(imageROI_3,rot_map_temp_3);

	Mat rot_map_4 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_4(rot_map_4, Rect(Point(0,0), rot_map_4.size()));
	rot_map_temp_4.copyTo(imageROI_4,rot_map_temp_4);

	Mat rot_map_5 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_5(rot_map_5, Rect(Point(0,0), rot_map_5.size()));
	rot_map_temp_5.copyTo(imageROI_5,rot_map_temp_5);

/*
	namedWindow("rotation_mat_1", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_2", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_3", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_4", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_5", WINDOW_AUTOSIZE);

	imshow("rotation_mat_1", rot_map_1);
	imshow("rotation_mat_2", rot_map_2);
	imshow("rotation_mat_3", rot_map_3);
	imshow("rotation_mat_4", rot_map_4);
	imshow("rotation_mat_5", rot_map_5);
*/
	accumulation_mat(rot_map_1, orb_sift_surf_area);
	accumulation_mat(rot_map_2, orb_sift_surf_area);
	accumulation_mat(rot_map_3, orb_sift_surf_area);
	accumulation_mat(rot_map_4, orb_sift_surf_area);
	accumulation_mat(rot_map_5, orb_sift_surf_area);
}


void get_rot_mat_and_do_homo(Mat for_surf_1, Mat for_surf_2)
{
	Mat src1 = for_surf_1.clone(); // 새로운 맵
	Mat src2 = for_surf_2.clone(); // 원본 맵

	if (src1.empty() || src2.empty())
	{
		cerr << "Image load failed!" << endl;
		return;
	}
	Ptr<Feature2D> feature = ORB::create();
	// Ptr<Feature2D> feature = xfeatures2d::SURF::create();
	vector<KeyPoint> keypoints1, keypoints2;
	Mat desc1, desc2;
	feature->detectAndCompute(src1, Mat(), keypoints1, desc1);
	feature->detectAndCompute(src2, Mat(), keypoints2, desc2);
	Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_HAMMING);
	// Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_L1);
	vector<DMatch> matches;
	matcher->match(desc1, desc2, matches);
	std::sort(matches.begin(), matches.end());
	vector<DMatch> good_matches(matches.begin(), matches.begin() + 5);
	vector<Point2f> pts1, pts2;
	for (size_t i = 0; i < good_matches.size(); i++)
	{
		pts1.push_back(keypoints1[good_matches[i].queryIdx].pt);
		pts2.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}

	// 이미지 2개의 특징점 5개로 두점사이의 거리를 구해서 정수화 한다.
	vector<int> xy_distance;
	xy_distance.reserve(6); // 꽉차면 공간을 늘리니까 미리 +1개 해놓는다.
	for ( int i=0; i<good_matches.size(); i++ )
	{
		xy_distance.push_back(pow((pow((pts1[i].x-pts2[i].x),2)+pow((pts1[i].y-pts2[i].y),2)), 0.5));
		//printf("xy_distance : %d\n", xy_distance[i]);
	}

	// 정수화된 거리가 일정하면 이미지가 일치한것이므로 해당 정수의 빈도를 구한다.
	int max_distance = pow( (pow(src1.size().width,2)+pow(src1.size().height,2)), 0.5 ); // 대각선길이 = 얻을 수 있는 정수의 최대값
	int repeat_check[max_distance] = {0};
	for ( int i=0; i<good_matches.size(); i++ )
	{
		repeat_check[xy_distance[i]] += 1;
		// xy_distance[0]의 값이 10이면 repeat_check의 10번째 인덱스에 +1된다.
		// xy_distance[1]의 값이 7이면 repeat_check의 7번째 인덱스에 +1된다.
	}

	// 최대 빈도수를 얻는다.
	int accumulation_check = *max_element(repeat_check, repeat_check+max_distance);
	//printf("accumulation_check : %d\n", accumulation_check);

	// 최대 빈도수가 표본의 70%를 초과하면 아래 작업을 수행한다.
	acu_map_condition = int(good_matches.size()*0.7);
	if ( accumulation_check > acu_map_condition )
	{
		int get_move_distance = 0;
		for ( int i=0; i<max_distance; i++ )
		{
			// repeat_check의 몇번째 인덱스가 최대 빈도인지 찾는다.
			if ( accumulation_check == repeat_check[i] )
			{
				// 최대 빈도를 가진 인덱스를 찾았다.
				get_move_distance = i;
				//printf("get_move_distance try 1 : %d\n", i);
				// 인덱스와 일치하는 가장 상위점을 구해서 이동시킨다.
				for ( int j=0; j<good_matches.size(); j++ )
				{
					if ( xy_distance[j] == get_move_distance )
					{
						double x_move = pts2[j].x - pts1[j].x;
						double y_move = pts2[j].y - pts1[j].y;

						Mat temp_ready= Mat(src1.size(), src1.type(), Scalar(100));
						mat_translation(src1, temp_ready, Point2d(x_move,y_move));

						vector<uchar> for_jpg_buff;
						vector<int> param = vector<int>(2);
						param[0]=CV_IMWRITE_JPEG_QUALITY;
						param[1]=95;
						imencode(".jpg",temp_ready,for_jpg_buff,param);
						Mat for_surf_cal = imdecode(Mat(for_jpg_buff),CV_LOAD_IMAGE_GRAYSCALE);

						homography_final(for_surf_cal, orb_sift_surf_area);
						return;
					}
				}
			}
		}
	}
}

void homography_start(Mat for_surf_1, Mat for_surf_2)
{
	Mat src1 = for_surf_1.clone(); // 새로운 맵
	Mat src2 = for_surf_2.clone(); // 원본 맵

	if (src1.empty() || src2.empty()) {
		cerr << "Image load failed!" << endl;
		return;
	}

	Ptr<Feature2D> feature = ORB::create();
	// Ptr<Feature2D> feature = xfeatures2d::SURF::create();

	Mat desc1, desc2;
	vector<KeyPoint> keypoints1, keypoints2;
	feature->detectAndCompute(src1, Mat(), keypoints1, desc1);
	feature->detectAndCompute(src2, Mat(), keypoints2, desc2);

	Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_HAMMING);
	// Ptr<DescriptorMatcher> matcher = BFMatcher::create(NORM_L1);
	
	vector<DMatch> matches;
	matcher->match(desc1, desc2, matches);

	std::sort(matches.begin(), matches.end());
	vector<DMatch> good_matches(matches.begin(), matches.begin() + 5);
	
	vector<Point2f> pts1, pts2;
	for (size_t i = 0; i < good_matches.size(); i++)
	{
		pts1.push_back(keypoints1[good_matches[i].queryIdx].pt);
		pts2.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}

	rot_cen_for_homo.x = src1.size().width/2;
	rot_cen_for_homo.y = src1.size().height/2;

	vector<double> original_degree, temp_degree;
	for (int i=0; i<good_matches.size(); i++)
	{
		// +x -y 방향이니까 y는 부호를 바꿔줘야한다. //
		original_degree.push_back(atan2( -(pts2[i].y-rot_cen_for_homo.y), (pts2[i].x-rot_cen_for_homo.x) ));
		temp_degree.push_back(atan2( -(pts1[i].y-rot_cen_for_homo.y), (pts1[i].x-rot_cen_for_homo.x)));
	}

	// 반시계 + 
	Mat rot_mask_1 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[0]-temp_degree[0])*180.0/M_PI , 1);
	Mat rot_mask_2 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[1]-temp_degree[1])*180.0/M_PI , 1);
	Mat rot_mask_3 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[2]-temp_degree[2])*180.0/M_PI , 1);
	Mat rot_mask_4 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[3]-temp_degree[3])*180.0/M_PI , 1);
	Mat rot_mask_5 = getRotationMatrix2D(rot_cen_for_homo, (original_degree[4]-temp_degree[4])*180.0/M_PI , 1);

	// src1을 rot_map_rank_1에 담는다. temp_rot_1를 참조해서, 사이즈, 타입.
	Mat rot_map_temp_1, rot_map_temp_2, rot_map_temp_3, rot_map_temp_4, rot_map_temp_5;
	warpAffine(src1, rot_map_temp_1, rot_mask_1, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_2, rot_mask_2, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_3, rot_mask_3, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_4, rot_mask_4, src1.size(), INTER_LINEAR);
	warpAffine(src1, rot_map_temp_5, rot_mask_5, src1.size(), INTER_LINEAR);

	Mat rot_map_1 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_1(rot_map_1, Rect(Point(0,0), rot_map_1.size()));
	rot_map_temp_1.copyTo(imageROI_1,rot_map_temp_1);

	Mat rot_map_2 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_2(rot_map_2, Rect(Point(0,0), rot_map_2.size()));
	rot_map_temp_2.copyTo(imageROI_2,rot_map_temp_2);

	Mat rot_map_3 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_3(rot_map_3, Rect(Point(0,0), rot_map_3.size()));
	rot_map_temp_3.copyTo(imageROI_3,rot_map_temp_3);

	Mat rot_map_4 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_4(rot_map_4, Rect(Point(0,0), rot_map_4.size()));
	rot_map_temp_4.copyTo(imageROI_4,rot_map_temp_4);

	Mat rot_map_5 = Mat(src1.size(), src1.type(), Scalar(100));
	Mat imageROI_5(rot_map_5, Rect(Point(0,0), rot_map_5.size()));
	rot_map_temp_5.copyTo(imageROI_5,rot_map_temp_5);

/*
	namedWindow("rotation_mat_1", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_2", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_3", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_4", WINDOW_AUTOSIZE);
	namedWindow("rotation_mat_5", WINDOW_AUTOSIZE);

	imshow("rotation_mat_1", rot_map_1);
	imshow("rotation_mat_2", rot_map_2);
	imshow("rotation_mat_3", rot_map_3);
	imshow("rotation_mat_4", rot_map_4);
	imshow("rotation_mat_5", rot_map_5);
*/
	// 매칭을 보여주는 함수 //
	Mat dst;
	drawMatches(src1, keypoints1, src2, keypoints2, good_matches, dst,
		Scalar::all(-1), Scalar::all(-1), vector<char>(),
		DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
	moveWindow("dst", 100, 600); // 모니터의 좌측 상단이 원점이다. (+x -y)
	namedWindow("dst", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
	imshow("dst", dst);
	waitKey(1);

	get_rot_mat_and_do_homo(rot_map_1, temp_5);
	get_rot_mat_and_do_homo(rot_map_2, temp_5);
	get_rot_mat_and_do_homo(rot_map_3, temp_5);
	get_rot_mat_and_do_homo(rot_map_4, temp_5);
	get_rot_mat_and_do_homo(rot_map_5, temp_5);

}


// 맵 그리는 함수 //
void scanCallback(const sensor_msgs::LaserScan::ConstPtr& scan)
{

	if (remap_count > 5)
	{
		if ( orb_sift_surf_area.total() == 0 )
		{

			Mat mat_resize_for_surf;
			resize(assist_map, mat_resize_for_surf, Size(assist_map.cols*0.5,assist_map.rows*0.5), 0, 0, INTER_AREA);

			vector<uchar> for_jpg_buff;
			vector<int> param = vector<int>(2);
			param[0]=CV_IMWRITE_JPEG_QUALITY;
			param[1]=95;
			imencode(".jpg",mat_resize_for_surf,for_jpg_buff,param);
			Mat for_surf_cal = imdecode(Mat(for_jpg_buff),CV_LOAD_IMAGE_GRAYSCALE);

			temp_5 = for_surf_cal.clone(); // 다음 5장과 비교할 맵을 임시로 복사한다.
			orb_sift_surf_area = for_surf_cal.clone(); // 초기 원본을 만든다. 참조가 아닌 복사를 시킨다.

		}
		else
		{
			try
			{
				Mat mat_resize_for_surf;
				resize(assist_map, mat_resize_for_surf, Size(assist_map.cols*0.5,assist_map.rows*0.5), 0, 0, INTER_AREA);

				vector<uchar> for_jpg_buff;
				vector<int> param = vector<int>(2);
				param[0]=CV_IMWRITE_JPEG_QUALITY;
				param[1]=95;
				imencode(".jpg",mat_resize_for_surf,for_jpg_buff,param);
				Mat for_surf_cal = imdecode(Mat(for_jpg_buff),CV_LOAD_IMAGE_GRAYSCALE);

				homography_start(for_surf_cal, temp_5);
				temp_5 = for_surf_cal.clone();

			}
			catch(cv::Exception& e)
			{
				printf("can't homography\n");
			}

			moveWindow("map_window", 600, 100); // 모니터의 좌측 상단이 원점이다. (+x -y)
			namedWindow("map_window", WINDOW_AUTOSIZE); // WINDOW_AUTOSIZE = 할당된 행렬에 딱 맞게 크기를 생성함, 크기조절 불가
			imshow("map_window", orb_sift_surf_area);
			waitKey(1);

			imwrite("map.jpg",orb_sift_surf_area);

		}
		// 맵 갱신 //
		assist_map = assist_re_map.clone();
		remap_count = 0;
	}
	else
	{
		if( get_yaw == 0.0 )
		{
			printf("wait init\n");
			sleep(0.1);
		}
		else
		{
			// ydlidar_node가 발생시킨 scan토픽으로부터 전체 데이터 갯수를 획득 //
			int count = scan->scan_time / scan->time_increment;

			// my_array는 m_a_count 변수의 값을 보고 조정한다. //
			// 매번 수가 변하므로 사용 후 파기하고 다시 선언하는것이 좋다. //
			double my_array[1000][2];

			// 전체 데이터중 유효한 데이터를 찾는 부분 //
			int m_a_count = 0; // 유효한 거리값 측정 위한 선언
			for(int i = 0; i < count; i++)
			{
				float degree = RAD2DEG(scan->angle_min + scan->angle_increment * i);

				if( degree<180.0 && degree>-180.0 )
				{
					if( isinf(scan->ranges[i]) || scan->ranges[i]<0.1 || scan->ranges[i]>8.0 )
					{
					// ydlidar의 datasheet 참조 //
					// 최소 0.1m, 최대 8m의 측정을 보장한다. //
					// 무한대, 0.1m미만, 8m초과 값을 버린다. //
					}
					else
					{
						my_array[m_a_count][0] = degree;
						my_array[m_a_count][1] = scan->ranges[i];

						// openCV로 line을 생성하기 위한 좌표를 계산하고 확대 시킨다. //
						assist_detection.x = my_array[m_a_count][1]*cos(my_array[m_a_count][0]*M_PI/180.0)*assist_enlarge;
						assist_detection.y = -my_array[m_a_count][1]*sin(my_array[m_a_count][0]*M_PI/180.0)*assist_enlarge;

						// 맵의 중심으로 이동시킨다. //
						assist_detection.x =  assist_center.x + assist_detection.x;
						assist_detection.y =  assist_center.y + assist_detection.y;

						// center로 부터 detection까지 흰색으로(255), 굵기 10
						line(assist_map, assist_center, assist_detection, Scalar(255), 5);

						++m_a_count;
					}
				}
			}
			++remap_count;
		}
	}


}

int main(int argc, char **argv)
{

	ros::init(argc, argv, "draw_map_node"); // ROS 통신을 위한 노드 선언
	ros::NodeHandle n; // 노드 핸들러 선언

	ros::Subscriber imu_sub = n.subscribe("project_degree", 1, get_degree_from_imu);
	// degree_publisher.py에서 보내지는 project_degree 토픽을 읽어서 get_degree_from_imu함수를 실행한다.

	ros::Subscriber ydlidar_sub = n.subscribe<sensor_msgs::LaserScan>("/scan", 1, scanCallback);
	// ydlidar_node에서 보내지는 /scan 토픽을 읽어서 scanCallback함수를 실행한다. //
	ros::Subscriber scan_time_sub = n.subscribe("scan_pub_time_for_imu", 1, check_scan_stamp);
	// ydlidar의 scan값과 imu의 동기화를 위해서 함수를 실행한다.

	ros::spin();
	// spin에 의해서 위의 두 노드가 While처럼 무한 루프로 토픽이 들어올때마다 함수를 실행한다. //

	return 0;
}
